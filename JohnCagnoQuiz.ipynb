{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnny\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras; print(keras.__version__)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "\n",
    "epa = pd.read_csv(\"C:/Users/Johnny/Documents/UNH Notes and Documents 2018/Spring 2018/Neural Networks and ML/quiz/epa_cleaned_Data_2.csv\", sep=',')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Low': 13861, 'Medium': 5377, 'High': 370, nan: 130})\n",
      "Low       70.690534\n",
      "Medium    27.422481\n",
      "High       1.886985\n",
      "Name: Three_cat, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#EDA\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(epa[\"Three_cat\"]))\n",
    "print(epa[\"Three_cat\"].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset relevant columns \n",
    "epa_numerical = epa[[\"Test_Veh_Displacement__L_\", \"Rated_Horsepower\", \"__of_Gears\", \"Equivalent_Test_Weight__lbs__\", \"Axle_Ratio\", \"N_V_Ratio\", \"Three_cat\", \"THC_bin\", \"CO_bin\", \"CO2_cat\", \"NOx_cat\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset l,m,h\n",
    "\n",
    "vals = ['Low', 'Medium', 'High']\n",
    "\n",
    "lmh = epa_numerical[\"Three_cat\"].isin(vals)\n",
    "epa_numerical = epa_numerical[lmh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low       70.690534\n",
      "Medium    27.422481\n",
      "High       1.886985\n",
      "Name: Three_cat, dtype: float64\n",
      "Counter({'Low': 13861, 'Medium': 5377, 'High': 370, nan: 130})\n",
      "(19608, 11)\n"
     ]
    }
   ],
   "source": [
    "print(epa_numerical[\"Three_cat\"].value_counts(normalize=True) * 100)\n",
    "print(Counter(epa[\"Three_cat\"]))\n",
    "print(epa_numerical.shape)\n",
    "\n",
    "epa_numerical = epa_numerical.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "\n",
    "epa_numerical = pd.get_dummies(epa_numerical, columns=[\"THC_bin\", \"CO_bin\", \"CO2_cat\", \"NOx_cat\"], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset data into two class dataframes\n",
    "High_Low = (epa_numerical.loc[epa_numerical['Three_cat'].isin(['Low','High'])])\n",
    "\n",
    "Low = (epa_numerical.loc[epa_numerical['Three_cat'].isin(['Low'])])\n",
    "LowSample = Low.sample(frac=0.1)\n",
    "\n",
    "Medium = (epa_numerical.loc[epa_numerical['Three_cat'].isin(['Medium'])])\n",
    "MedSample = Medium.sample(frac=0.1)\n",
    "\n",
    "lowmed = [Medium, LowSample]\n",
    "medlow = [MedSample, Low]\n",
    "\n",
    "Low_Medium = pd.concat(lowmed)\n",
    "Medium_Low = pd.concat(medlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Medium': 5160, 'Low': 1261})\n",
      "Counter({'Low': 12611, 'High': 322})\n",
      "Counter({'Low': 12611, 'Medium': 516})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(Low_Medium[\"Three_cat\"]))\n",
    "print(Counter(High_Low[\"Three_cat\"]))\n",
    "print(Counter(Medium_Low[\"Three_cat\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADASYN function\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "def ten_adasyn(dataframe):\n",
    "    dataframe = dataframe.sample(frac=0.7)\n",
    "    X = dataframe.loc[:, dataframe.columns != \"Three_cat\"]\n",
    "    Y = dataframe[\"Three_cat\"]\n",
    "    X_adasyn, y_adasyn = ADASYN().fit_sample(X,Y)\n",
    "    data_adasyn = pd.concat([pd.DataFrame(X_adasyn, columns = ['Test_Veh_Displacement__L_', 'Rated_Horsepower', '__of_Gears','Equivalent_Test_Weight__lbs__', 'Axle_Ratio', 'N_V_Ratio','THC_bin_High', 'THC_bin_Low', 'CO_bin_High', 'CO_bin_Low','CO2_cat_High', 'CO2_cat_Low', 'CO2_cat_Medium', 'NOx_cat_High','NOx_cat_Low', 'NOx_cat_Medium']), pd.DataFrame(y_adasyn, columns = ['Three_cat'])],axis = 1)\n",
    "    dataframe = data_adasyn\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run adasyn 5 times\n",
    "High_Low1 = ten_adasyn(High_Low)\n",
    "High_Low2 = ten_adasyn(High_Low)\n",
    "High_Low3 = ten_adasyn(High_Low)\n",
    "High_Low4 = ten_adasyn(High_Low)\n",
    "High_Low5 = ten_adasyn(High_Low)\n",
    "\n",
    "#concatenate datasets\n",
    "hl = [High_Low1, High_Low2, High_Low3, High_Low4, High_Low5]\n",
    "Highlow = pd.concat(hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run adasyn 5 times\n",
    "\n",
    "Lowmedium1 = ten_adasyn(Low_Medium)\n",
    "Lowmedium2 = ten_adasyn(Low_Medium)\n",
    "Lowmedium3 = ten_adasyn(Low_Medium)\n",
    "Lowmedium4 = ten_adasyn(Low_Medium)\n",
    "Lowmedium5 = ten_adasyn(Low_Medium)\n",
    "\n",
    "#concatenate datasets\n",
    "lm = [Lowmedium1, Lowmedium2, Lowmedium3, Lowmedium4, Lowmedium5]\n",
    "LowMedium = pd.concat(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run adasyn 5 times\n",
    "\n",
    "Medium_Low1 = ten_adasyn(Medium_Low)\n",
    "Medium_Low2 = ten_adasyn(Medium_Low)\n",
    "Medium_Low3 = ten_adasyn(Medium_Low)\n",
    "Medium_Low4 = ten_adasyn(Medium_Low)\n",
    "Medium_Low5 = ten_adasyn(Medium_Low)\n",
    "\n",
    "#concatenate datasets\n",
    "ml = [Medium_Low1, Medium_Low2, Medium_Low3, Medium_Low4, Medium_Low5]\n",
    "MediumLow = pd.concat(ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95855, 17)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate all datafrmaes and drop duplicates\n",
    "\n",
    "all_frames = [Highlow,LowMedium,MediumLow]\n",
    "oversampled_df = pd.concat(all_frames)\n",
    "oversampled_df = oversampled_df.drop_duplicates()\n",
    "oversampled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#round one hot encoded variables\n",
    "oversampled_df = oversampled_df.round({'THC_bin_High':0, 'THC_bin_Low':0, 'CO_bin_High':0, 'CO_bin_Low':0,\n",
    "       'CO2_cat_High':0, 'CO2_cat_Low':0, 'CO2_cat_Medium':0, 'NOx_cat_High':0,\n",
    "       'NOx_cat_Low':0, 'NOx_cat_Medium':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "76747/76747 [==============================] - 1s 16us/step - loss: 0.4401 - acc: 0.8203\n",
      "Epoch 2/5\n",
      "76747/76747 [==============================] - 1s 9us/step - loss: 0.3794 - acc: 0.8448\n",
      "Epoch 3/5\n",
      "76747/76747 [==============================] - 1s 9us/step - loss: 0.3693 - acc: 0.8445\n",
      "Epoch 4/5\n",
      "76747/76747 [==============================] - 1s 9us/step - loss: 0.3620 - acc: 0.8447\n",
      "Epoch 5/5\n",
      "76747/76747 [==============================] - 1s 9us/step - loss: 0.3554 - acc: 0.8517\n",
      "19187/19187 [==============================] - 0s 25us/step\n",
      "test_acc: 0.8566216709292338\n"
     ]
    }
   ],
   "source": [
    "##THC Model##\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "#subset and split\n",
    "X = oversampled_df[['Test_Veh_Displacement__L_', 'Rated_Horsepower', '__of_Gears',\n",
    "       'Equivalent_Test_Weight__lbs__', 'Axle_Ratio', 'N_V_Ratio']]\n",
    "\n",
    "y = oversampled_df[['THC_bin_High']]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.2, random_state = 0)\n",
    "\n",
    "#scale data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "#contruct model\n",
    "thc_model = models.Sequential()\n",
    "thc_model.add(Dense(6, input_dim=6, activation='relu')) \n",
    "thc_model.add(Dense(30, activation='relu'))\n",
    "thc_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "thc_model.compile(optimizer='rmsprop',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "thc_model.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "#validate\n",
    "test_loss, test_acc = thc_model.evaluate(X_test, y_test)\n",
    "\n",
    "print('test_acc:', test_acc)\n",
    "\n",
    "pred = thc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "77211/77211 [==============================] - 1s 12us/step - loss: 0.4613 - acc: 0.8230\n",
      "Epoch 2/7\n",
      "77211/77211 [==============================] - 1s 7us/step - loss: 0.4069 - acc: 0.8334\n",
      "Epoch 3/7\n",
      "77211/77211 [==============================] - 1s 8us/step - loss: 0.3944 - acc: 0.8400\n",
      "Epoch 4/7\n",
      "77211/77211 [==============================] - 1s 10us/step - loss: 0.3874 - acc: 0.8424\n",
      "Epoch 5/7\n",
      "77211/77211 [==============================] - 1s 11us/step - loss: 0.3815 - acc: 0.8441\n",
      "Epoch 6/7\n",
      "77211/77211 [==============================] - 1s 9us/step - loss: 0.3757 - acc: 0.8455\n",
      "Epoch 7/7\n",
      "77211/77211 [==============================] - 1s 8us/step - loss: 0.3701 - acc: 0.8452\n",
      "19303/19303 [==============================] - 0s 20us/step\n",
      "test_acc: 0.8431331917318552\n"
     ]
    }
   ],
   "source": [
    "##CO Model##\n",
    "\n",
    "X = oversampled_df[['Test_Veh_Displacement__L_', 'Rated_Horsepower', '__of_Gears',\n",
    "       'Equivalent_Test_Weight__lbs__', 'Axle_Ratio', 'N_V_Ratio']]\n",
    "\n",
    "y = oversampled_df[['CO_bin_High']]\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.2, random_state = 0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "co_model = models.Sequential()\n",
    "co_model.add(Dense(6, input_dim=6, activation='relu')) \n",
    "co_model.add(Dense(30, activation='relu'))\n",
    "co_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "co_model.compile(optimizer='rmsprop',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# fit the NN\n",
    "co_model.fit(X_train, y_train, epochs=7, batch_size=150)\n",
    "\n",
    "test_loss, test_acc = co_model.evaluate(X_test, y_test)\n",
    "\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "77211/77211 [==============================] - 1s 17us/step - loss: 0.5942 - acc: 0.7816\n",
      "Epoch 2/8\n",
      "77211/77211 [==============================] - 1s 10us/step - loss: 0.5036 - acc: 0.8039\n",
      "Epoch 3/8\n",
      "77211/77211 [==============================] - 1s 11us/step - loss: 0.4918 - acc: 0.8046\n",
      "Epoch 4/8\n",
      "77211/77211 [==============================] - 1s 12us/step - loss: 0.4859 - acc: 0.8053\n",
      "Epoch 5/8\n",
      "77211/77211 [==============================] - 1s 11us/step - loss: 0.4819 - acc: 0.8073\n",
      "Epoch 6/8\n",
      "77211/77211 [==============================] - 1s 12us/step - loss: 0.4783 - acc: 0.8084\n",
      "Epoch 7/8\n",
      "77211/77211 [==============================] - 1s 11us/step - loss: 0.4750 - acc: 0.8091\n",
      "Epoch 8/8\n",
      "77211/77211 [==============================] - 1s 11us/step - loss: 0.4718 - acc: 0.8089\n",
      "19303/19303 [==============================] - 0s 21us/step\n",
      "test_acc: 0.8117391079137753\n"
     ]
    }
   ],
   "source": [
    "##CO2 Model##\n",
    "\n",
    "X = oversampled_df[['Test_Veh_Displacement__L_', 'Rated_Horsepower', '__of_Gears',\n",
    "       'Equivalent_Test_Weight__lbs__', 'Axle_Ratio', 'N_V_Ratio']]\n",
    "\n",
    "y = oversampled_df[['CO2_cat_High', 'CO2_cat_Low', 'CO2_cat_Medium']]\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.2, random_state = 0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "co2_model = models.Sequential()\n",
    "co2_model.add(Dense(6, input_dim=6, activation='relu')) \n",
    "co2_model.add(Dense(30, activation='relu'))\n",
    "co2_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "co2_model.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# fit the NN\n",
    "co2_model.fit(X_train, y_train, epochs=8, batch_size=160)\n",
    "\n",
    "test_loss, test_acc = co2_model.evaluate(X_test, y_test)\n",
    "\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "77211/77211 [==============================] - 1s 15us/step - loss: 0.5625 - acc: 0.7909\n",
      "Epoch 2/8\n",
      "77211/77211 [==============================] - 1s 11us/step - loss: 0.5066 - acc: 0.8064\n",
      "Epoch 3/8\n",
      "77211/77211 [==============================] - 1s 8us/step - loss: 0.4960 - acc: 0.8059\n",
      "Epoch 4/8\n",
      "77211/77211 [==============================] - 1s 7us/step - loss: 0.4892 - acc: 0.8053\n",
      "Epoch 5/8\n",
      "77211/77211 [==============================] - 1s 8us/step - loss: 0.4843 - acc: 0.8057\n",
      "Epoch 6/8\n",
      "77211/77211 [==============================] - 1s 8us/step - loss: 0.4805 - acc: 0.8065\n",
      "Epoch 7/8\n",
      "77211/77211 [==============================] - 1s 8us/step - loss: 0.4764 - acc: 0.8078\n",
      "Epoch 8/8\n",
      "77211/77211 [==============================] - 1s 8us/step - loss: 0.4729 - acc: 0.8085\n",
      "19303/19303 [==============================] - 0s 24us/step\n",
      "test_acc: 0.8151582655576649\n"
     ]
    }
   ],
   "source": [
    "##NOX Model##\n",
    "\n",
    "X = oversampled_df[['Test_Veh_Displacement__L_', 'Rated_Horsepower', '__of_Gears',\n",
    "       'Equivalent_Test_Weight__lbs__', 'Axle_Ratio', 'N_V_Ratio']]\n",
    "\n",
    "y = oversampled_df[['CO2_cat_High', 'CO2_cat_Low', 'CO2_cat_Medium']]\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.2, random_state = 0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "nox_model = models.Sequential()\n",
    "nox_model.add(Dense(6, input_dim=6, activation='relu')) \n",
    "nox_model.add(Dense(30, activation='relu'))\n",
    "nox_model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "nox_model.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# fit the NN\n",
    "nox_model.fit(X_train, y_train, epochs=8, batch_size=160)\n",
    "\n",
    "test_loss, test_acc = nox_model.evaluate(X_test, y_test)\n",
    "\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'oversampled_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-166e5a6e827d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# print(Counter(oversampled_df[\"THC_bin_High\"]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moversampled_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'oversampled_df' is not defined"
     ]
    }
   ],
   "source": [
    "# print(Counter(oversampled_df[\"THC_bin_High\"]))\n",
    "oversampled_df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
